{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "import torch \n",
    "from torch.utils.data import Dataset, DataLoader,WeightedRandomSampler\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# from pyt_ex import neural_net.Ann as ann \n",
    "from tqdm import tqdm\n",
    "\n",
    "Input_Matrix = pd.read_excel('Data/as of 2020 Historical Data.xlsx', sheet_name='Input Matrix')\n",
    "\n",
    "Target_Matrix = pd.read_excel('/home/sai/Pyt-Ex/Data/as of 2020 Historical Data.xlsx', sheet_name='Target Matrix')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyt_ex import Ann as neural_network \n",
    "from pyt_ex import ClassifierDataset, FastTensorDataLoader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Unnamed: 1</th>\n      <th>Inputs (at Landfall)</th>\n      <th>Unnamed: 3</th>\n      <th>Unnamed: 4</th>\n      <th>Unnamed: 5</th>\n      <th>Unnamed: 6</th>\n      <th>First Landfall Location</th>\n      <th>Unnamed: 8</th>\n      <th>Second Landfall Location</th>\n      <th>Unnamed: 10</th>\n      <th>Third Landfall Location</th>\n      <th>Unnamed: 12</th>\n      <th>Fourth Landfall Location</th>\n      <th>Unnamed: 14</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Year</td>\n      <td>Storm</td>\n      <td>Population Affected</td>\n      <td>Pressure (mbar)</td>\n      <td>Wind Speed (mph)</td>\n      <td>Storm Surge (ft)</td>\n      <td>Precip (inches)</td>\n      <td>Latitude</td>\n      <td>Longtitude</td>\n      <td>Latitude</td>\n      <td>Longtitude</td>\n      <td>Latitude</td>\n      <td>Longtitude</td>\n      <td>Latitude</td>\n      <td>Longtitude</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020</td>\n      <td>Bertha</td>\n      <td>710000</td>\n      <td>1005</td>\n      <td>51.75</td>\n      <td>1.32</td>\n      <td>15</td>\n      <td>32.9</td>\n      <td>79.7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>Cristobal</td>\n      <td>7200000</td>\n      <td>990</td>\n      <td>51.75</td>\n      <td>6.2</td>\n      <td>13.65</td>\n      <td>29.3</td>\n      <td>89.8</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>Fay</td>\n      <td>22500000</td>\n      <td>999</td>\n      <td>51.75</td>\n      <td>2.67</td>\n      <td>6.97</td>\n      <td>39.4</td>\n      <td>74.4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>Hanna</td>\n      <td>2000000</td>\n      <td>973</td>\n      <td>92</td>\n      <td>6.24</td>\n      <td>15.49</td>\n      <td>26.8</td>\n      <td>97.3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>92</th>\n      <td>NaN</td>\n      <td>H. Earl</td>\n      <td>1600000</td>\n      <td>987</td>\n      <td>80.5</td>\n      <td>5.3</td>\n      <td>16.38</td>\n      <td>30.1</td>\n      <td>85.7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>93</th>\n      <td>NaN</td>\n      <td>TS. Frances</td>\n      <td>17000000</td>\n      <td>990</td>\n      <td>51.75</td>\n      <td>5.1</td>\n      <td>11.38</td>\n      <td>28.2</td>\n      <td>96.9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>94</th>\n      <td>NaN</td>\n      <td>H. Georges</td>\n      <td>11200000</td>\n      <td>964</td>\n      <td>103.5</td>\n      <td>9</td>\n      <td>38.46</td>\n      <td>24.5</td>\n      <td>81.8</td>\n      <td>30.4</td>\n      <td>88.9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>NaN</td>\n      <td>TS. Hermine</td>\n      <td>2200000</td>\n      <td>1000</td>\n      <td>40.25</td>\n      <td>0</td>\n      <td>1</td>\n      <td>29.1</td>\n      <td>90.9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>NaN</td>\n      <td>H. Mitch</td>\n      <td>7400000</td>\n      <td>989</td>\n      <td>63.25</td>\n      <td>3</td>\n      <td>7</td>\n      <td>26.2</td>\n      <td>81.9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>97 rows × 15 columns</p>\n</div>",
      "text/plain": "   Unnamed: 0   Unnamed: 1 Inputs (at Landfall)       Unnamed: 3  \\\n0        Year        Storm  Population Affected  Pressure (mbar)   \n1        2020       Bertha               710000             1005   \n2         NaN    Cristobal              7200000              990   \n3         NaN          Fay             22500000              999   \n4         NaN        Hanna              2000000              973   \n..        ...          ...                  ...              ...   \n92        NaN      H. Earl              1600000              987   \n93        NaN  TS. Frances             17000000              990   \n94        NaN   H. Georges             11200000              964   \n95        NaN  TS. Hermine              2200000             1000   \n96        NaN     H. Mitch              7400000              989   \n\n          Unnamed: 4        Unnamed: 5       Unnamed: 6  \\\n0   Wind Speed (mph)  Storm Surge (ft)  Precip (inches)   \n1              51.75              1.32               15   \n2              51.75               6.2            13.65   \n3              51.75              2.67             6.97   \n4                 92              6.24            15.49   \n..               ...               ...              ...   \n92              80.5               5.3            16.38   \n93             51.75               5.1            11.38   \n94             103.5                 9            38.46   \n95             40.25                 0                1   \n96             63.25                 3                7   \n\n   First Landfall Location  Unnamed: 8 Second Landfall Location Unnamed: 10  \\\n0                 Latitude  Longtitude                 Latitude  Longtitude   \n1                     32.9        79.7                        0           0   \n2                     29.3        89.8                        0           0   \n3                     39.4        74.4                        0           0   \n4                     26.8        97.3                        0           0   \n..                     ...         ...                      ...         ...   \n92                    30.1        85.7                        0           0   \n93                    28.2        96.9                        0           0   \n94                    24.5        81.8                     30.4        88.9   \n95                    29.1        90.9                        0           0   \n96                    26.2        81.9                        0           0   \n\n   Third Landfall Location Unnamed: 12 Fourth Landfall Location Unnamed: 14  \n0                 Latitude  Longtitude                 Latitude  Longtitude  \n1                        0           0                        0           0  \n2                        0           0                        0           0  \n3                        0           0                        0           0  \n4                        0           0                        0           0  \n..                     ...         ...                      ...         ...  \n92                       0           0                        0           0  \n93                       0           0                        0           0  \n94                       0           0                        0           0  \n95                       0           0                        0           0  \n96                       0           0                        0           0  \n\n[97 rows x 15 columns]"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Input_Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_columns = ['Year', 'Storm', 'Ry_Damage', '2016_USD', 'Impact_Level', 'IL0', 'IL1', 'IL2', 'IL3', 'IL4', 'IL5', 'Check']\n",
    "\n",
    "Target_Matrix.drop(['Unnamed: 11', 'Unnamed: 13'], axis=1, inplace=True)\n",
    "\n",
    "Target_Matrix.set_axis(target_columns, axis=1, inplace=True)\n",
    "\n",
    "# Target_Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = ['Year', 'Storm', 'Population_Affected', 'Pressure(mbar)', 'Wind_Speed(mph)', 'Storm_Surge(ft)', 'Precip(inches)', 'First_Latitude', 'First_Longtitude', 'Second_Latitude', 'Second_Longtitude', 'Third_Latitude', 'Third_Longtitude', 'Fourth_Latitude', 'Fourth_Longtitude']\n",
    "\n",
    "Input_Matrix.set_axis(input_columns, axis=1, inplace=True)\n",
    "\n",
    "Input_Matrix.drop([0], inplace = True)\n",
    "\n",
    "Input_Matrix.reset_index(drop=True, inplace=True)\n",
    "\n",
    "Input_Matrix.drop(['Year', 'Storm'], axis=1, inplace=True)\n",
    "\n",
    "# Input_Matrix\n",
    "\n",
    "df = Input_Matrix\n",
    "df['Impact_Level'] = Target_Matrix['Impact_Level'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:xlabel='Impact_Level', ylabel='count'>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 432x288 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = 'Impact_Level', data=df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierDataset(Dataset):\n",
    "    '''\n",
    "    to set data in a block.\n",
    "    this dataset will be used by the dataloader to pass the data\n",
    "    into the model.\n",
    "    X = float\n",
    "    y = long\n",
    "    '''\n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_distribution(obj):\n",
    "    count_dict = {\n",
    "        \"rating_0\": 0,\n",
    "        \"rating_1\": 0,\n",
    "        \"rating_2\": 0,\n",
    "        \"rating_3\": 0,\n",
    "        \"rating_4\": 0,\n",
    "        \"rating_5\": 0,\n",
    "    }\n",
    "    \n",
    "    for i in obj:\n",
    "        if i == 0: \n",
    "            count_dict['rating_0'] += 1\n",
    "        elif i == 1: \n",
    "            count_dict['rating_1'] += 1\n",
    "        elif i == 2: \n",
    "            count_dict['rating_2'] += 1\n",
    "        elif i == 3: \n",
    "            count_dict['rating_3'] += 1\n",
    "        elif i == 4: \n",
    "            count_dict['rating_4'] += 1  \n",
    "        elif i == 5: \n",
    "            count_dict['rating_5'] += 1              \n",
    "        else:\n",
    "            print(\"Check classes.\")\n",
    "            \n",
    "    return count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:28<00:00, 88.57s/it]\n"
     ]
    }
   ],
   "source": [
    "logger = {}\n",
    "seeds = [2, 3, 7, 11, 13, 17, 19, 23, 29, 31]\n",
    "\n",
    "device = 'cpu'#torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  \n",
    "torch.manual_seed(10) \n",
    "\n",
    "with open('config/Input.yaml') as File:\n",
    "    dic = yaml.load(File, Loader=yaml.FullLoader)\n",
    "\n",
    "for i in tqdm(dic):\n",
    "    logger[i] = {}\n",
    "\n",
    "    batch_size = dic[i][\"batch_size\"]\n",
    "    for j in seeds:\n",
    "        # print(i)\n",
    "        X = df.iloc[:, 0:-1]\n",
    "        y = df.iloc[:, -1]\n",
    "\n",
    "        # Split into train+val and test\n",
    "        X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=j)\n",
    "\n",
    "        # Split train into train-val\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.1, stratify=y_trainval, random_state=j)\n",
    "\n",
    "        scaler = MinMaxScaler()\n",
    "\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_val = scaler.transform(X_val)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "        X_val, y_val = np.array(X_val), np.array(y_val)\n",
    "        X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "\n",
    "        X = np.array(scaler.transform(X))\n",
    "        y = np.array(y)\n",
    "\n",
    "        # train_dataset = ClassifierDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).long())\n",
    "        # val_dataset = ClassifierDataset(torch.from_numpy(X_val).float(), torch.from_numpy(y_val).long())\n",
    "        # test_dataset = ClassifierDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test).long())\n",
    "        # dataset = ClassifierDataset(torch.from_numpy(X).float(), torch.from_numpy(y).long())\n",
    "\n",
    "        # target_list = []\n",
    "        # for _, t in train_dataset:\n",
    "        #     target_list.append(t)\n",
    "            \n",
    "        # target_list = torch.tensor(target_list)\n",
    "        # target_list = target_list[torch.randperm(len(target_list))] \n",
    "\n",
    "        # class_count = [i for i in get_class_distribution(y_train).values()]\n",
    "        # class_weights = 1./torch.tensor(class_count, dtype=torch.float) \n",
    "\n",
    "        # class_weights_all = class_weights[target_list]\n",
    "\n",
    "        # weighted_sampler = WeightedRandomSampler(\n",
    "        #     weights=class_weights_all,\n",
    "        #     num_samples=len(class_weights_all),\n",
    "        #     replacement=True\n",
    "        # )\n",
    "\n",
    "        # train_loader = FastTensorDataLoader(dataset=train_dataset,\n",
    "        #                     batch_size=batch_size,\n",
    "        #                     sampler=weighted_sampler\n",
    "        #                         )\n",
    "\n",
    "        # val_loader = FastTensorDataLoader(dataset=val_dataset, batch_size=batch_size)\n",
    "        # test_loader = FastTensorDataLoader(dataset=test_dataset, batch_size=batch_size) \n",
    "        # full_loader = FastTensorDataLoader(dataset=dataset)\n",
    "\n",
    "        train_loader = FastTensorDataLoader(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).long(), batch_size=batch_size)\n",
    "\n",
    "        val_loader = FastTensorDataLoader(torch.from_numpy(X_val).float(), torch.from_numpy(y_val).long(), batch_size=batch_size)\n",
    "        test_loader = FastTensorDataLoader(torch.from_numpy(X_test).float(), torch.from_numpy(y_test).long(), batch_size=batch_size) \n",
    "        full_loader = FastTensorDataLoader(torch.from_numpy(X).float(), torch.from_numpy(y).long())\n",
    "\n",
    "        ann = neural_network.Ann(dic[i])\n",
    "        ann = ann.to(device)\n",
    "        ann.fit(train_dataloader=train_loader, \n",
    "                    val_dataloader=val_loader, \n",
    "                    test_dataloader=test_loader, \n",
    "                    full_dataloader=full_loader ) \n",
    "        # unique = [0, 1, 2, 3, 4, 5]\n",
    "        # if ann.final_acc*100 >= 70:\n",
    "        logger[i][j] = {}\n",
    "        logger[i][j]['y_test'] = y_test\n",
    "        logger[i][j][\"train_acc_list\"] = ann.train_acc_list\n",
    "        logger[i][j][\"val_acc_list\"] = ann.val_acc_list\n",
    "        logger[i][j][\"train_loss_list\"] = ann.train_loss_list\n",
    "        logger[i][j][\"val_loss_list\"] = ann.val_loss_list\n",
    "        logger[i][j][\"test_output\"] = ann.test_Output\n",
    "        logger[i][j][\"test_acc\"] = ann.test_acc\n",
    "        logger[i][j][\"Predictions\"], logger[i][j]['Final_acc'] = ann.predictions, ann.final_acc\n",
    "        logger[i][j]['classification_report'] = classification_report(y_test, ann.test_Output, labels = unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22916666666666666\n",
      "0.4479166666666667\n",
      "0.3333333333333333\n",
      "0.4479166666666667\n",
      "0.2708333333333333\n",
      "0.3645833333333333\n",
      "0.3645833333333333\n",
      "0.4270833333333333\n",
      "0.5520833333333334\n",
      "0.4895833333333333\n"
     ]
    }
   ],
   "source": [
    "for i in seeds:\n",
    "    print(logger[1][i]['Final_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'TWO'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-9c024b77ba25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TWO'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Final_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'TWO'"
     ]
    }
   ],
   "source": [
    "print(logger['TWO'][2]['Final_acc'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7604166666666666,\n",
       " 0.7916666666666666,\n",
       " 0.7916666666666666,\n",
       " 0.84375,\n",
       " 0.7604166666666666,\n",
       " 0.8020833333333334,\n",
       " 0.7708333333333334,\n",
       " 0.7291666666666666,\n",
       " 0.7395833333333334]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = list(logger['TWO'].keys())\n",
    "l = []\n",
    "for i in s:\n",
    "    l.append(logger['TWO'][i]['Final_acc'])\n",
    "l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.55, 0.45, 0.4, 0.7, 0.45, 0.6, 0.55, 0.4, 0.45]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = list(logger['TWO'].keys())\n",
    "t = []\n",
    "for i in s:\n",
    "    t.append(logger['TWO'][i]['test_acc'])\n",
    "t "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchbnn as bnn\n",
    "from torch import nn\n",
    "\n",
    "model = nn.Sequential(\n",
    "    bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=15, out_features=50),\n",
    "    nn.Tanh(),\n",
    "    nn.BatchNorm1d(50),\n",
    "    bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=50, out_features=2)\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model_plots(i):\n",
    "#     from matplotlib.gridspec import GridSpec\n",
    "#     fig = plt.figure(figsize=(20, 10))\n",
    "#     gs = GridSpec(nrows=2, ncols=2)\n",
    "\n",
    "#     ax0 = fig.add_subplot(gs[0, 0])\n",
    "#     ax0.plot(plots[i][\"train_acc_list\"], label = 'train_acc_list')\n",
    "#     ax0.plot(plots[i][\"val_acc_list\"], label = 'val_acc_list')\n",
    "#     ax0.legend()\n",
    "#     ax0.title.set_text('Training and validation accuracy')\n",
    "#     ax0.set(xlabel='Iterations', ylabel='Accuracy')\n",
    "\n",
    "#     ax1 = fig.add_subplot(gs[0, 1])\n",
    "#     ax1.plot(plots[i][\"train_loss_list\"], label = 'train_loss_list')\n",
    "#     ax1.plot(plots[i][\"val_loss_list\"], label = 'val_loss_list')\n",
    "#     ax1.legend() \n",
    "#     ax1.title.set_text('Training and validation loss')\n",
    "#     ax1.set(xlabel='Iterations', ylabel='CrossEntropyLoss')\n",
    "\n",
    "#     ax2 = fig.add_subplot(gs[1, 0])\n",
    "#     confusion_matrix_df = pd.DataFrame(confusion_matrix(y_test, plots[i][\"test_output\"]))\n",
    "#     ax2 = sns.heatmap(confusion_matrix_df, annot=True, cmap='Blues')\n",
    "#     ax2.title.set_text('Test Confusion matrix')\n",
    "#     ax2.set(xlabel='Predicted Label', ylabel='True Label')\n",
    "\n",
    "#     # ax3 = fig.add_subplot()\n",
    "#     ax3 = fig.add_subplot(gs[1, 1])\n",
    "#     confusion_matrix_df = pd.DataFrame(confusion_matrix(y, plots[i][\"Predictions\"]))\n",
    "#     ax3 = sns.heatmap(confusion_matrix_df, annot=True, cmap='Blues')\n",
    "#     ax3.title.set_text('Full Confusion matrix, final_acc = '+str( plots[i]['Final_acc']))\n",
    "#     ax3.set(xlabel='Predicted Label', ylabel='True Label')\n",
    "\n",
    "#     plt.show()\n",
    "\n",
    "# models = [i for i in plots.keys()]\n",
    "# models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2021-11-15 19:33:52 (running for 00:00:00.13)<br>Memory usage on this node: 2.5/7.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/12 CPUs, 0/0 GPUs, 0.0/3.66 GiB heap, 0.0/1.83 GiB objects<br>Result logdir: /home/sai/ray_results/train_mnist_2021-11-15_19-33-52<br>Number of trials: 3/3 (3 PENDING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">   lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_mnist_dfda9_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.001</td></tr>\n",
       "<tr><td>train_mnist_dfda9_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.01 </td></tr>\n",
       "<tr><td>train_mnist_dfda9_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.1  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /home/sai/.local/lib/python3.8/site-packages/redis/connection.py:77: UserWarning: redis-py works best with hiredis. Please consider installing\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   warnings.warn(msg)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /home/sai/.local/lib/python3.8/site-packages/redis/connection.py:77: UserWarning: redis-py works best with hiredis. Please consider installing\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   warnings.warn(msg)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /home/sai/.local/lib/python3.8/site-packages/redis/connection.py:77: UserWarning: redis-py works best with hiredis. Please consider installing\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   warnings.warn(msg)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m /home/sai/.local/lib/python3.8/site-packages/redis/connection.py:77: UserWarning: redis-py works best with hiredis. Please consider installing\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m   warnings.warn(msg)\n",
      "\u001b[2m\u001b[36m(pid=1172)\u001b[0m /home/sai/.local/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "\u001b[2m\u001b[36m(pid=1172)\u001b[0m   return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "\u001b[2m\u001b[36m(pid=1173)\u001b[0m /home/sai/.local/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "\u001b[2m\u001b[36m(pid=1173)\u001b[0m   return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "\u001b[2m\u001b[36m(pid=1174)\u001b[0m /home/sai/.local/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "\u001b[2m\u001b[36m(pid=1174)\u001b[0m   return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial train_mnist_dfda9_00001 completed. Last result: \n",
      "Trial train_mnist_dfda9_00000 completed. Last result: \n",
      "Trial train_mnist_dfda9_00002 completed. Last result: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2021-11-15 19:33:57 (running for 00:00:04.90)<br>Memory usage on this node: 2.7/7.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/12 CPUs, 0/0 GPUs, 0.0/3.66 GiB heap, 0.0/1.83 GiB objects<br>Result logdir: /home/sai/ray_results/train_mnist_2021-11-15_19-33-52<br>Number of trials: 3/3 (3 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">   lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_mnist_dfda9_00000</td><td>TERMINATED</td><td>172.28.228.115:1174</td><td style=\"text-align: right;\">0.001</td></tr>\n",
       "<tr><td>train_mnist_dfda9_00001</td><td>TERMINATED</td><td>172.28.228.115:1172</td><td style=\"text-align: right;\">0.01 </td></tr>\n",
       "<tr><td>train_mnist_dfda9_00002</td><td>TERMINATED</td><td>172.28.228.115:1173</td><td style=\"text-align: right;\">0.1  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-15 19:33:57,762\tINFO tune.py:630 -- Total run time: 5.03 seconds (4.90 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from ray import tune\n",
    "from ray.tune.examples.mnist_pytorch import get_data_loaders, ConvNet, train, test\n",
    "\n",
    "\n",
    "def train_mnist(config):\n",
    "    train_loader, test_loader = get_data_loaders()\n",
    "    model = ConvNet()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=config[\"lr\"])\n",
    "    for i in range(10):\n",
    "        train(model, optimizer, train_loader)\n",
    "        acc = test(model, test_loader)\n",
    "        # tune.report(mean_accuracy=acc)\n",
    "\n",
    "\n",
    "analysis = tune.run(\n",
    "    train_mnist, config={\"lr\": tune.grid_search([0.001, 0.01, 0.1])})\n",
    "\n",
    "# print(\"Best config: \", analysis.get_best_config(metric=\"mean_accuracy\"))\n",
    "\n",
    "# Get a dataframe for analyzing trial results.\n",
    "df = analysis.dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_accuracy</th>\n",
       "      <th>time_this_iter_s</th>\n",
       "      <th>done</th>\n",
       "      <th>timesteps_total</th>\n",
       "      <th>episodes_total</th>\n",
       "      <th>training_iteration</th>\n",
       "      <th>trial_id</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>date</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>time_total_s</th>\n",
       "      <th>pid</th>\n",
       "      <th>hostname</th>\n",
       "      <th>node_ip</th>\n",
       "      <th>time_since_restore</th>\n",
       "      <th>timesteps_since_restore</th>\n",
       "      <th>iterations_since_restore</th>\n",
       "      <th>config/lr</th>\n",
       "      <th>logdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.209375</td>\n",
       "      <td>0.282337</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>3db57_00000</td>\n",
       "      <td>4b361979e5384f7c9fa25fd3ce9cc569</td>\n",
       "      <td>2021-11-15_19-29-24</td>\n",
       "      <td>1637022564</td>\n",
       "      <td>2.721422</td>\n",
       "      <td>805</td>\n",
       "      <td>DESKTOP-3CVVCKA</td>\n",
       "      <td>172.28.228.115</td>\n",
       "      <td>2.721422</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>/home/sai/ray_results/train_mnist_2021-11-15_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.796875</td>\n",
       "      <td>0.304014</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>3db57_00001</td>\n",
       "      <td>dcc4a581f1644dc7a7c5d79479a48dff</td>\n",
       "      <td>2021-11-15_19-29-26</td>\n",
       "      <td>1637022566</td>\n",
       "      <td>2.914158</td>\n",
       "      <td>808</td>\n",
       "      <td>DESKTOP-3CVVCKA</td>\n",
       "      <td>172.28.228.115</td>\n",
       "      <td>2.914158</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.010</td>\n",
       "      <td>/home/sai/ray_results/train_mnist_2021-11-15_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.865625</td>\n",
       "      <td>0.301122</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>3db57_00002</td>\n",
       "      <td>c3817e5a42d34d1398f7cc77e633521f</td>\n",
       "      <td>2021-11-15_19-29-26</td>\n",
       "      <td>1637022566</td>\n",
       "      <td>2.997246</td>\n",
       "      <td>809</td>\n",
       "      <td>DESKTOP-3CVVCKA</td>\n",
       "      <td>172.28.228.115</td>\n",
       "      <td>2.997246</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.100</td>\n",
       "      <td>/home/sai/ray_results/train_mnist_2021-11-15_1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_accuracy  time_this_iter_s   done  timesteps_total  episodes_total  \\\n",
       "0       0.209375          0.282337  False              NaN             NaN   \n",
       "1       0.796875          0.304014  False              NaN             NaN   \n",
       "2       0.865625          0.301122  False              NaN             NaN   \n",
       "\n",
       "   training_iteration     trial_id                     experiment_id  \\\n",
       "0                  10  3db57_00000  4b361979e5384f7c9fa25fd3ce9cc569   \n",
       "1                  10  3db57_00001  dcc4a581f1644dc7a7c5d79479a48dff   \n",
       "2                  10  3db57_00002  c3817e5a42d34d1398f7cc77e633521f   \n",
       "\n",
       "                  date   timestamp  time_total_s  pid         hostname  \\\n",
       "0  2021-11-15_19-29-24  1637022564      2.721422  805  DESKTOP-3CVVCKA   \n",
       "1  2021-11-15_19-29-26  1637022566      2.914158  808  DESKTOP-3CVVCKA   \n",
       "2  2021-11-15_19-29-26  1637022566      2.997246  809  DESKTOP-3CVVCKA   \n",
       "\n",
       "          node_ip  time_since_restore  timesteps_since_restore  \\\n",
       "0  172.28.228.115            2.721422                        0   \n",
       "1  172.28.228.115            2.914158                        0   \n",
       "2  172.28.228.115            2.997246                        0   \n",
       "\n",
       "   iterations_since_restore  config/lr  \\\n",
       "0                        10      0.001   \n",
       "1                        10      0.010   \n",
       "2                        10      0.100   \n",
       "\n",
       "                                              logdir  \n",
       "0  /home/sai/ray_results/train_mnist_2021-11-15_1...  \n",
       "1  /home/sai/ray_results/train_mnist_2021-11-15_1...  \n",
       "2  /home/sai/ray_results/train_mnist_2021-11-15_1...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "name": "python369jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  },
  "orig_nbformat": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}